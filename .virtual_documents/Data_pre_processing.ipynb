import numpy as np
from matplotlib import pyplot as plt
import pandas as pd





df = pd.read_csv('dataset/data-pre-processing/Data.csv')


#X represents all the feature variables.
X = df.iloc[:,:-1].values
#Y represents the dependant variable
Y = df.iloc[:,-1].values


print(X,Y)





from sklearn.impute import SimpleImputer
###Helps replace all missing fileds in with column average
imputer = SimpleImputer(missing_values=np.nan,strategy='mean')
###Find all the missing values.ake sure to choose numeric columns for this strategy
imputer.fit(X[:,1:3])
###Apply transform to missing values
X[:,1:3]=imputer.transform(X[:,1:3])


print(X)





from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
#apply onehot encoding to column 1 to transform categorical data into a numeric value
ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough')
X=np.array(ct.fit_transform(X))


print(X)





from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
Y=le.fit_transform(Y)


print(Y)





from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=1)


print(x_train)


print(x_test)


print(y_train)


print(y_test)





from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train[:,4:] = sc.fit_transform(x_train[:,4:])
x_test[:,4:] = sc.transform(x_test[:,4:])


print(x_train)


print(x_test)
